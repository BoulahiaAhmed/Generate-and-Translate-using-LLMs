# Generate-and-Translate-using-LLMs

![dcdc](https://github.com/BoulahiaAhmed/Generate-and-Translate-using-LLMs/assets/45523231/4edfd235-3da6-40d5-956c-766410bada77)

We will explore the process of fine-tuning large language models (LLMs) for a specific task: summarizing English news articles in Arabic and generating an Arabic title. 

We will focus on two powerful models, **Gemma-7b** and **Llama3-8b**, and walk through each step required to achieve this task. 

**1- Dataset Creation**: How to gather and prepare the data necessary for fine-tuning. 

**2-  Creation**: Crafting effective prompts to guide the models in performing the desired tasks.

**3- Model Fine-Tuning**: Using Unsloth AI to fine-tune our models specifically for summarization and title generation. 

By the end, you will have a clear understanding of how to adapt these LLMs to perform task-oriented applications, leveraging their capabilities to produce meaningful outputs in a different language. Letâ€™s get started!
